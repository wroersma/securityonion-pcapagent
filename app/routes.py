import ipaddress
import ujson
import logging
import os
import time
import datetime
import sqlite3

from elasticsearch import Elasticsearch
from datetime import datetime
from time import mktime
from flask import jsonify
from flask import render_template
from flask import request
from flask_restful import reqparse

from app import app, db, d

from app.forms import SearchForm

with open('config.json', 'r') as cfg:
    config = ujson.load(cfg)

logging.basicConfig(filename=config["logFile"], level=logging.DEBUG)

# Create the database to store clients
# commented out to import from global app
#db = sqlite3.connect(config["sensorDB"])
#d = db.cursor()

intervals = (
    ('weeks', 604800),  # 60 * 60 * 24 * 7
    ('days', 86400),    # 60 * 60 * 24
    ('hours', 3600),    # 60 * 60
    ('minutes', 60),
    ('seconds', 1),
    )


def check_avail(pcaptime):
    oldest = min(os.listdir(config["pcapPath"]), key=os.path.getctime)
    if oldest < pcaptime:
        return "BAD"
    else:
        return "GOOD"


def display_time(seconds, granularity=2):
    result = []

    for name, count in intervals:
        value = seconds // count
        if value:
            seconds -= value * count
            if value == 1:
                name = name.rstrip('s')
            result.append("{} {}".format(value, name))
    return ', '.join(result[:granularity])


def get_oldest_pcapfile():
    with app.app_context():
        now = time.time()
        oldest = min(os.listdir(config["pcapPath"]), key=os.path.getctime)
        filename = os.path.abspath(oldest)
        filectime = os.path.getatime(filename)
        age = (now - filectime)
        agehuman = display_time(age)
        results = jsonify(filename=filename,
                          createtime=filectime,
                          status=STATUS,
                          history=agehuman)

    return results


def validateip(ip):
    try:
        result = ipaddress.ip_address(ip)
        return result
    except ValueError:
        return False


def converttime(time):
    try:
        return blah
    except:
        return False


def addjob(sensor,stenoquery):
    db = sqlite3.connect(config["sensorDB"])
    d = db.cursor()

    # Create Sensor Table
    try:
        # Create Jobs Table
        d.execute('CREATE TABLE IF NOT EXISTS jobs  (jobid integer PRIMARY KEY AUTOINCREMENT, sensorid text, query text, jobstatus int)')
        db.commit()
        print("I added the table if it wasn't there.")
        d.execute('INSERT INTO jobs (sensorid, query, jobstatus) VALUES (?,?,0)', (sensor, stenoquery))
        db.commit()
        print(d.lastrowid)
        return str(d.lastrowid)

    except Exception as err:
        print("Something is wrong with the taterbase")
        print('Query Failed: %s\nError: %s' % (thequery, str(err)))


def getconn(connid):
    # Connect to Elastic and get information about the connection.
    esserver = config["esserver"]
    es = Elasticsearch(esserver)
    search = es.search(index="*:logstash-*",
                       doc_type="doc", body={"query": {"bool": {"must": {"match": {'_id': esid}}}}})
    hits = search['hits']['total']
    if hits > 0:
        for result in search['hits']['hits']:
            # Check for src/dst IP/ports
            if 'source_ip' in result['_source']:
                src = result['_source']['source_ip']
            if 'destination_ip' in result['_source']:
                dst = result['_source']['destination_ip']
            if 'source_port' in result['_source']:
                srcport = result['_source']['source_port']
            if 'destination_port' in result['_source']:
                dstport = result['_source']['destination_port']

            # Check if bro_conn log
            if 'uid' in result['_source']:
                uid = result['_source']['uid']
                if isinstance(uid, list):
                    uid = result['_source']['uid'][0]
                if uid[0] == "C":
                  es_type = "bro_conn"
                  bro_query = uid

            # Check if X509 log
            elif 'id' in result['_source']:
                x509id = result['_source']['id']
                if x509id[0] -- "F":
                    es_type = "bro_files"
                    bro_query = x509id

            # Check if Bro files log
            elif 'fuid' in result['_source']:
                fuid = result['_source']['fuid']
                if fuid[0] -- "F":
                    es_type = "bro_files"
                    bro_query = fuid
         
            # If we didn't match any of the above, we will build a query
            # from the info that we have (src/dst ip/port)
            else:
                es_type = "bro_conn"
                bro_query = str(src) + " AND " + str(srcport) + " AND " + str(dst) + " AND " + str(dstport)

            # Get timestamp from original result and format it for search
            estimestamp = datetime.strptime(result['_source']['@timestamp'], "%Y-%m-%dT%H:%M:%S.%fZ")
            epochtimestamp = mktime(estimestamp.timetuple())
            st = epochtimestamp - 1800
            et = epochtimestamp + 1800
            st_es = st * 1000
            et_es = et * 1000

            # If we have a Bro Files log, lets get set to look for a connection log
            if result['_source']['event_type'] == "bro_files":
                es_type = "bro_conn"
                bro_query = ujson.dumps(result['_source']['uid']).strip('[').strip(']').strip('\"')
            else:
                es_type = None
                bro_query = None
            # Set query string for second search,
            query_string = 'event_type:' + str(es_type) + ' AND ' + str(bro_query)
            query = '{"query": {"bool": {"must": [{"query_string": {"query": "' + str(query_string) + '","analyze_wildcard": true}},{"range": {"@timestamp":{ "gte": "' + str(st_es) + '", "lte": "' + str(et_es) + '", "format": "epoch_millis"}}}]}}}'
            # Search for a Bro connection log
            search = es.search(index="*:logstash-*", doc_type="doc", body=query)
            hits = search['hits']['total']
            if hits > 0:
                for result in search['hits']['hits']:
                    # Build the rest of the query for Steno
                    src = result['_source']['source_ip']
                    dst = result['_source']['destination_ip']
                    srcport = result['_source']['source_port']
                    dstport = result['_source']['destination_port']
                    duration = result['_source']['duration']
                    estimestamp = datetime.strptime(result['_source']['@timestamp'], "%Y-%m-%dT%H:%M:%S.%fZ")
                    epochtimestamp = mktime(estimestamp.timetuple())
                    epochminus = int(epochtimestamp - int(duration) - 120)
                    epochplus = int(epochtimestamp + int(duration) + 120)
                    pcapbefore = datetime.utcfromtimestamp(epochminus).strftime('%Y-%m-%dT%H:%M:%S:%fZ')
                    pcapafter = datetime.utcfromtimestamp(epochminus).strftime('%Y-%m-%dT%H:%M:%S:%fZ')
                    sensor = result['_source']['sensor_name']
                    stenoquery = "before %s and after %s and host %s and host %s and port %s and port %s" % (pcapbefore,
                                                                                                             pcapafter,
                                                                                                             src,
                                                                                                             dst,
                                                                                                             srcport,
                                                                                                             dstport)
                    return [sensor, stenoquery]
                    #print sensor,stenoquery
            else:
               print("No hits for second query!")
    else:
        print('No hits for first query')

#TODO Check sensor before trying to do something.
def checksensor(sensor):
    return sensor


@app.route('/')
def hello_world():
    return 'Hello World!'


@app.route('/pcapstatus')
def get_status():
    return get_oldest_pcapfile()


@app.route('/search', methods=['GET', 'POST'])
def search():
    if request.method == 'POST':
        form = SearchForm(request.form)
        if form.validate_on_submit():
            src = string(request.args[src])
            return '''<h1>The Source is {}</h1>'''.format(src)
    elif request.method == 'GET':
        form = SearchForm()
    return render_template('search.html', title='Search Pcap', form=form)


# Give it a conn id and let it do its thing.
@app.route('/searchbycid')
@app.route('/searchapi', methods=['GET', 'POST'])
def searchapi():
    parser = reqparse.RequestParser()
    parser.add_argument('src')
    parser.add_argument('dst')
    parser.add_argument('srcport')
    parser.add_argument('dstport')
    parser.add_argument('start')
    parser.add_argument('end')
    parser.add_argument('sensor')
    args = parser.parse_args()
    if validateip(args['src']) is False:
        return "%s is not a valid IP" % args['src']
    if validateip(args['dst']) is False:
        return "%s is not a valid IP" % args['dst']

    stenoquery = "before %s and after %s and host %s and host %s and port %s and port %s" % (args['end'], args['start'], args['src'], args['dst'], args['srcport'], args['dstport'])
    sensor = (args['sensor'])
    print('Adding the Job')
    result = addjob(sensor, stenoquery)
    return "Job ID %s has been added" % result


@app.route('/jobs', methods=['GET'])
def jobs():
    # Get all the jobs
    db = sqlite3.connect(config["sensorDB"])
    d = db.cursor()

    d.execute("SELECT * from jobs")
    jobsdata = d.fetchall()
    return render_template('jobs.html', jobsdata=jobsdata)


@app.route('/getjob')
def getjob():
    """Take a job from the queue"""
    db = sqlite3.connect(config["sensorDB"])
    d = db.cursor()

    parser = reqparse.RequestParser()
    parser.add_argument('sensor')
    args = parser.parse_args()
    sensor = args['sensor']
    d.execute('SELECT * from jobs WHERE jobstatus=0 and sensorid=? ORDER BY jobid ASC', (sensor,))
    job = d.fetchone()
    return jsonify(jobid=job[0], sensor=job[1], query=job[2], status=job[3])


@app.route('/updatejob')
def updatejob():
    """Update job page route."""
    db = sqlite3.connect(config["sensorDB"])
    d = db.cursor()
    parser = reqparse.RequestParser()
    parser.add_argument('jobid')
    parser.add_argument('jobstatus')
    args = parser.parse_args()
    jobid = args['jobid']
    jobstatus = args['jobstatus']

    d.execute('UPDATE jobs SET jobstatus=? WHERE jobid=?', (jobstatus,jobid))


@app.route('/sensor', methods=['POST'])
def sensor():
    """Sensor registration page route."""
    db = sqlite3.connect(config["sensorDB"])
    d = db.cursor()
    parser = reqparse.RequestParser()
    parser.add_argument('sensor')
    parser.add_argument('oldestpcap')
    parser.add_argument('lastcheckin')
    args = parser.parse_args()

    # Create Sensor Table if it is not there
    try:
        d.execute('CREATE TABLE IF NOT EXISTS sensors (id text PRIMARY KEY, oldestpcap int, lastcheckin int')
        d.execute(f"INSERT INT sensors (id, oldestpcap, lastcheckin') VALUES ({args['sensor']}, "
                  f"{args['oldestpcap']}, {args['lastcheckin']})")
    except:
        print('Something is broken')


#TODO Have something to handle the delivery of the pcap
@app.route('/uploadjob', methods=['POST'])
def uploadjob():
    return 'yo'

